{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779aa6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from pyntcloud import PyntCloud\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1c137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the functions are taken from pykitti https://github.com/utiasSTARS/pykitti/blob/master/pykitti/utils.py\n",
    "def load_velo_scan(file):\n",
    "    \"\"\"\n",
    "    Load and parse a velodyne binary file\n",
    "    \"\"\"\n",
    "    scan = np.fromfile(file, dtype=np.float32)\n",
    "    return scan.reshape((-1, 4))\n",
    "\n",
    "def load_poses(file):\n",
    "    \"\"\"\n",
    "    Load and parse ground truth poses\n",
    "    \"\"\"\n",
    "    tmp_poses = np.genfromtxt(file, delimiter=' ').reshape(-1, 3, 4)\n",
    "    poses = np.repeat(np.expand_dims(np.eye(4), 0), tmp_poses.shape[0], axis=0)\n",
    "    poses[:, 0:3, :] = tmp_poses\n",
    "    return poses\n",
    "\n",
    "def read_calib_file(filepath):\n",
    "    \"\"\"\n",
    "    Read in a calibration file and parse into a dictionary\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            key, value = line.split(':', 1)\n",
    "            try:\n",
    "                data[key] = np.array([float(x) for x in value.split()])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# This part of the code is taken from the semanticKITTI API\n",
    "def open_label(filename):\n",
    "    \"\"\" \n",
    "    Open raw scan and fill in attributes\n",
    "    \"\"\"\n",
    "    # check filename is string\n",
    "    if not isinstance(filename, str):\n",
    "        raise TypeError(\"Filename should be string type, \"\n",
    "                        \"but was {type}\".format(type=str(type(filename))))\n",
    "\n",
    "    # if all goes well, open label\n",
    "    label = np.fromfile(filename, dtype=np.uint32)\n",
    "    label = label.reshape((-1))\n",
    "\n",
    "    return label\n",
    "\n",
    "def set_label(label, points):\n",
    "    \"\"\" \n",
    "    Set points for label not from file but from np\n",
    "    \"\"\"\n",
    "    # check label makes sense\n",
    "    if not isinstance(label, np.ndarray):\n",
    "        raise TypeError(\"Label should be numpy array\")\n",
    "\n",
    "    # only fill in attribute if the right size\n",
    "    if label.shape[0] == points.shape[0]:\n",
    "        sem_label = label & 0xFFFF  # semantic label in lower half\n",
    "        inst_label = label >> 16    # instance id in upper half\n",
    "    else:\n",
    "        print(\"Points shape: \", points.shape)\n",
    "        print(\"Label shape: \", label.shape)\n",
    "        raise ValueError(\"Scan and Label don't contain same number of points\")\n",
    "\n",
    "    # sanity check\n",
    "    assert((sem_label + (inst_label << 16) == label).all())\n",
    "\n",
    "    return sem_label, inst_label\n",
    "\n",
    "def transform_point_cloud(x1, R, t):\n",
    "    \"\"\"\n",
    "    Transforms the point cloud using the giver transformation paramaters\n",
    "    \n",
    "    Args:\n",
    "        x1  (np array): points of the point cloud [n,3]\n",
    "        R   (np array): estimated rotation matrice [3,3]\n",
    "        t   (np array): estimated translation vectors [3,1]\n",
    "    Returns:\n",
    "        x1_t (np array): points of the transformed point clouds [n,3]\n",
    "    \"\"\"\n",
    "    x1_t = (np.matmul(R, x1.transpose()) + t).transpose()\n",
    "\n",
    "    return x1_t\n",
    "\n",
    "def sorted_alphanum(file_list_ordered):\n",
    "    \"\"\"\n",
    "    Sorts the list alphanumerically\n",
    "    Args:\n",
    "        file_list_ordered (list): list of files to be sorted\n",
    "    Return:\n",
    "        sorted_list (list): input list sorted alphanumerically\n",
    "    \"\"\"\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "\n",
    "    def alphanum_key(key):\n",
    "        return [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "\n",
    "    sorted_list = sorted(file_list_ordered, key=alphanum_key)\n",
    "\n",
    "    return sorted_list\n",
    "\n",
    "def get_file_list(path, extension=None):\n",
    "    \"\"\"\n",
    "    Build a list of all the files in the provided path\n",
    "    Args:\n",
    "        path (str): path to the directory \n",
    "        extension (str): only return files with this extension\n",
    "    Return:\n",
    "        file_list (list): list of all the files (with the provided extension) sorted alphanumerically\n",
    "    \"\"\"\n",
    "    if extension is None:\n",
    "        file_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    else:\n",
    "        file_list = [\n",
    "            os.path.join(path, f)\n",
    "            for f in os.listdir(path)\n",
    "            if os.path.isfile(os.path.join(path, f)) and os.path.splitext(f)[1] == extension\n",
    "        ]\n",
    "    file_list = sorted_alphanum(file_list)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def get_folder_list(path):\n",
    "    \"\"\"\n",
    "    Build a list of all the folders in the provided path\n",
    "    Args:\n",
    "        path (str): path to the directory \n",
    "    Returns:\n",
    "        folder_list (list): list of all the folders sorted alphanumerically\n",
    "    \"\"\"\n",
    "    folder_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    folder_list = sorted_alphanum(folder_list)\n",
    "    \n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb8e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_consecutive_point_cloud(pc_s, R1, t1, R2, t2):\n",
    "    pc = np.matmul(np.linalg.inv(R2), (np.matmul(R1, pc_s.transpose()) + t1) - t2).transpose()\n",
    "    return pc\n",
    "\n",
    "def get_eigen_features(pc, n_neighbors=48):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        pc (np array): points of the point cloud [n, 3]\n",
    "        n_neighbors (int): number of neighbors selected\n",
    "    Returns: \n",
    "        pc_feature (np array): features of the point cloud [n, 14]\n",
    "    \"\"\"\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "    pointcloud = PyntCloud.from_instance(\"open3d\", pcd)\n",
    "\n",
    "    neighbors = pointcloud.get_neighbors(k=n_neighbors)\n",
    "    eigenvalues = pointcloud.add_scalar_field(\"eigen_values\", k_neighbors=neighbors)\n",
    "\n",
    "    anisotropy = pointcloud.add_scalar_field(\"anisotropy\", ev=eigenvalues)\n",
    "    curvature = pointcloud.add_scalar_field(\"curvature\", ev=eigenvalues)\n",
    "    eigenentropy = pointcloud.add_scalar_field(\"eigenentropy\", ev=eigenvalues)\n",
    "    eigensum = pointcloud.add_scalar_field(\"eigen_sum\", ev=eigenvalues)\n",
    "    linearity = pointcloud.add_scalar_field(\"linearity\", ev=eigenvalues)\n",
    "    omnivariance = pointcloud.add_scalar_field(\"omnivariance\", ev=eigenvalues)\n",
    "    planarity = pointcloud.add_scalar_field(\"planarity\", ev=eigenvalues)\n",
    "    sphericity = pointcloud.add_scalar_field(\"sphericity\", ev=eigenvalues)\n",
    "\n",
    "    pc_feature = np.asarray(pointcloud.points)\n",
    "\n",
    "    return pc_feature\n",
    "\n",
    "def cal_chamfer_dist(source_pts, target_pts, length):\n",
    "    if(target_pts.size == 0):\n",
    "        return 24 * length * length\n",
    "    source_pcd = o3d.geometry.PointCloud()\n",
    "    source_pcd.points = o3d.utility.Vector3dVector(source_pts[:, 0:3].reshape(-1, 3))\n",
    "    target_pcd = o3d.geometry.PointCloud()\n",
    "    target_pcd.points = o3d.utility.Vector3dVector(target_pts[:, 0:3].reshape(-1, 3))\n",
    "    \n",
    "    source2target_dists = source_pcd.compute_point_cloud_distance(target_pcd)\n",
    "    target2source_dists = target_pcd.compute_point_cloud_distance(source_pcd)\n",
    "    source2target_dists = np.asarray(source2target_dists)\n",
    "    target2source_dists = np.asarray(target2source_dists)\n",
    "    source2target_dists = np.square(source2target_dists)\n",
    "    target2source_dists = np.square(target2source_dists)\n",
    "    chamfer_dist = source2target_dists.mean() + target2source_dists.mean()\n",
    "    \n",
    "    return chamfer_dist\n",
    "\n",
    "def find_neighbors(voxel_center, source_pts, target_pts, length):\n",
    "    source_idx = np.where((source_pts[:,0] > voxel_center[0] - length) & (source_pts[:,0] < voxel_center[0] + length) & \n",
    "                          (source_pts[:,1] > voxel_center[1] - length) & (source_pts[:,1] < voxel_center[1] + length) & \n",
    "                          (source_pts[:,2] > voxel_center[2] - length) & (source_pts[:,2] < voxel_center[2] + length))[0]\n",
    "    target_idx = np.where((target_pts[:,0] > voxel_center[0] - length) & (target_pts[:,0] < voxel_center[0] + length) & \n",
    "                          (target_pts[:,1] > voxel_center[1] - length) & (target_pts[:,1] < voxel_center[1] + length) & \n",
    "                          (target_pts[:,2] > voxel_center[2] - length) & (target_pts[:,2] < voxel_center[2] + length))[0]\n",
    "    \n",
    "    source_pts = source_pts[source_idx, :]\n",
    "    target_pts = target_pts[target_idx, :]\n",
    "    \n",
    "    return source_pts, target_pts, source_idx\n",
    "\n",
    "def chamfer_dist(source_pts, target_pts, length=1):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(source_pts)\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=length * 2)\n",
    "    voxels_all = voxel_grid.get_voxels()\n",
    "    \n",
    "    chamfer = np.ones(source_pts.shape[0]) * -1\n",
    "    \n",
    "    for voxel in voxels_all:\n",
    "        voxel_center = voxel_grid.get_voxel_center_coordinate(voxel.grid_index)\n",
    "        source_neighbors_pts, target_neighbors_pts, source_neighbors_idx = find_neighbors(voxel_center, source_pts, target_pts, length)\n",
    "        chamfer[source_neighbors_idx] = cal_chamfer_dist(source_neighbors_pts, target_neighbors_pts, length)\n",
    "    \n",
    "    return chamfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c472a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation_result(pc, Rt):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc.reshape(-1, 3))\n",
    "    pcd.transform(Rt)\n",
    "    \n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def plot_consecutive_point_cloud(pc_s, pc_t):\n",
    "    pcd_s = o3d.geometry.PointCloud()\n",
    "    pcd_s.points = o3d.utility.Vector3dVector(pc_s[:, 0:3])\n",
    "    pcd_s.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "    pcd_t = o3d.geometry.PointCloud()\n",
    "    pcd_t.points = o3d.utility.Vector3dVector(pc_t[:, 0:3])\n",
    "    pcd_t.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "    o3d.visualization.draw_geometries([pcd_s, pcd_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165a2100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "folder_list_test = get_folder_list('\\\\Workspace\\\\SceneFlow\\\\datasets\\\\argoverse\\\\val')\n",
    "file_list_test = []\n",
    "\n",
    "for folder in folder_list_test:\n",
    "    file_list = get_file_list(folder)\n",
    "    for file in file_list:\n",
    "        file_list_test.append(file)\n",
    "\n",
    "print(len(file_list_test))\n",
    "        \n",
    "poses = load_poses('\\\\Workspace\\\\SceneFlow\\\\lib\\\\argoverse2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6b9d5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "for idx, file in enumerate(file_list_test):\n",
    "    if idx < 18:\n",
    "        continue\n",
    "    pc_data = np.load(file)\n",
    "    pc_s = pc_data['pc1']\n",
    "    pc_t = pc_data['pc2']\n",
    "    flow_gt = pc_data['flow']\n",
    "    \n",
    "    pc_s_w = get_transformation_result(pc_s, poses[idx])\n",
    "    flow_estimate = pc_s_w - pc_s\n",
    "    \n",
    "#     pc_s[:, [1, 2]] = pc_s[:, [2, 1]]\n",
    "#     pc_t[:, [1, 2]] = pc_t[:, [2, 1]]\n",
    "    \n",
    "#     R1 = np.eye(3)\n",
    "#     t1 = np.zeros((3, 1))\n",
    "#     R2 = poses[idx, 0:3, 0:3]\n",
    "#     t2 = poses[idx, 0:3, 3].reshape(3, 1)\n",
    "\n",
    "#     def match_consecutive_point_cloud(pc_s, R1, t1, R2, t2):\n",
    "#         pc = np.matmul(np.linalg.inv(R2), (np.matmul(R1, pc_s.transpose()) + t1) - t2).transpose()\n",
    "#         return pc\n",
    "\n",
    "#     pc_s = match_consecutive_point_cloud(pc_s, R1, t1, R2, t2)\n",
    "#     plot_consecutive_point_cloud(pc_s, pc_t)\n",
    "    \n",
    "    # Extract eigen features\n",
    "    eigen_features_s = get_eigen_features(pc_s_w)\n",
    "    eigen_features_t = get_eigen_features(pc_t)\n",
    "    \n",
    "    # Calculate Chamfer distance\n",
    "    dist = np.array(chamfer_dist(pc_s_w, pc_t))\n",
    "    \n",
    "    n1 = pc_s_w.shape[0]\n",
    "    n2 = pc_t.shape[0]\n",
    "    if n1 >= 16384:\n",
    "        sample_idx1 = np.random.choice(n1, 16384, replace=False)\n",
    "    else:\n",
    "        sample_idx1 = np.concatenate((np.arange(n1), np.random.choice(n1, 16384 - n1, replace=True)), axis=-1)\n",
    "    if n2 >= 16384:\n",
    "        sample_idx2 = np.random.choice(n2, 16384, replace=False)\n",
    "    else:\n",
    "        sample_idx2 = np.concatenate((np.arange(n2), np.random.choice(n2, 16384 - n2, replace=True)), axis=-1)\n",
    "        \n",
    "    pc_s_w = pc_s_w[sample_idx1, :]\n",
    "    pc_s = pc_s[sample_idx1, :]\n",
    "    pc_t = pc_t[sample_idx2, :]\n",
    "    eigen_features_s = eigen_features_s[sample_idx1, :]\n",
    "    eigen_features_t = eigen_features_t[sample_idx2, :]\n",
    "    dist = dist[sample_idx1]\n",
    "    flow_gt = flow_gt[sample_idx1, :]\n",
    "    flow_estimate = flow_estimate[sample_idx1, :]\n",
    "    \n",
    "    plot_consecutive_point_cloud(pc_s_w, pc_t)\n",
    "\n",
    "#     np.savez_compressed(os.path.join('\\\\Workspace\\\\SceneFlow\\\\datasets', 'argoverse_dynamic_estimation', '{}.npz'.format(str(idx).zfill(6))),\n",
    "#                         pc1=pc_s_w,\n",
    "#                         pc2=pc_t,\n",
    "#                         eigen_features_s=eigen_features_s,\n",
    "#                         eigen_features_t=eigen_features_t,\n",
    "#                         chamfer_dist=dist,\n",
    "#                         flow_gt=flow_gt,\n",
    "#                         flow_estimate=flow_estimate)\n",
    "    print(idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14521745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
