{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb34783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "import open3d as o3d\n",
    "import pickle\n",
    "import threading\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from ai import cs\n",
    "from pyntcloud import PyntCloud\n",
    "import rpointhop\n",
    "import utils\n",
    "import kitti_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb62d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lidar_to_cam = np.asarray([-1.857739385241e-03, -9.999659513510e-01, -8.039975204516e-03, -4.784029760483e-03, -6.481465826011e-03, 8.051860151134e-03, -9.999466081774e-01, -7.337429464231e-02, 9.999773098287e-01, -1.805528627661e-03, -6.496203536139e-03, -3.339968064433e-01])\n",
    "# lidar_to_cam = lidar_to_cam.reshape(3,4)\n",
    "# ones = np.zeros((1,4))\n",
    "# ones[0,3] = 1\n",
    "# lidar_to_cam = np.concatenate((lidar_to_cam, ones),axis=0)\n",
    "\n",
    "lidar_to_cam = np.ones((4, 4))\n",
    "\n",
    "LOG_FOUT = open('argoverse3.txt', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574bc727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the functions are taken from pykitti https://github.com/utiasSTARS/pykitti/blob/master/pykitti/utils.py\n",
    "def load_velo_scan(file):\n",
    "    \"\"\"\n",
    "    Load and parse a velodyne binary file\n",
    "    \"\"\"\n",
    "    scan = np.fromfile(file, dtype=np.float32)\n",
    "    return scan.reshape((-1, 4))\n",
    "\n",
    "def load_poses(file):\n",
    "    \"\"\"\n",
    "    Load and parse ground truth poses\n",
    "    \"\"\"\n",
    "    tmp_poses = np.genfromtxt(file, delimiter=' ').reshape(-1, 3, 4)\n",
    "    poses = np.repeat(np.expand_dims(np.eye(4), 0), tmp_poses.shape[0], axis=0)\n",
    "    poses[:, 0:3, :] = tmp_poses\n",
    "    return poses\n",
    "\n",
    "def read_calib_file(filepath):\n",
    "    \"\"\"\n",
    "    Read in a calibration file and parse into a dictionary\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            key, value = line.split(':', 1)\n",
    "            try:\n",
    "                data[key] = np.array([float(x) for x in value.split()])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    return data\n",
    "\n",
    "# This part of the code is taken from the semanticKITTI API\n",
    "def open_label(filename):\n",
    "    \"\"\" \n",
    "    Open raw scan and fill in attributes\n",
    "    \"\"\"\n",
    "    # check filename is string\n",
    "    if not isinstance(filename, str):\n",
    "        raise TypeError(\"Filename should be string type, \"\n",
    "                        \"but was {type}\".format(type=str(type(filename))))\n",
    "\n",
    "    # if all goes well, open label\n",
    "    label = np.fromfile(filename, dtype=np.uint32)\n",
    "    label = label.reshape((-1))\n",
    "\n",
    "    return label\n",
    "\n",
    "def set_label(label, points):\n",
    "    \"\"\" \n",
    "    Set points for label not from file but from np\n",
    "    \"\"\"\n",
    "    # check label makes sense\n",
    "    if not isinstance(label, np.ndarray):\n",
    "        raise TypeError(\"Label should be numpy array\")\n",
    "\n",
    "    # only fill in attribute if the right size\n",
    "    if label.shape[0] == points.shape[0]:\n",
    "        sem_label = label & 0xFFFF  # semantic label in lower half\n",
    "        inst_label = label >> 16    # instance id in upper half\n",
    "    else:\n",
    "        print(\"Points shape: \", points.shape)\n",
    "        print(\"Label shape: \", label.shape)\n",
    "        raise ValueError(\"Scan and Label don't contain same number of points\")\n",
    "\n",
    "    # sanity check\n",
    "    assert((sem_label + (inst_label << 16) == label).all())\n",
    "\n",
    "    return sem_label, inst_label\n",
    "\n",
    "def transform_point_cloud(x1, R, t):\n",
    "    \"\"\"\n",
    "    Transforms the point cloud using the giver transformation paramaters\n",
    "    \n",
    "    Args:\n",
    "        x1  (np array): points of the point cloud [n,3]\n",
    "        R   (np array): estimated rotation matrice [3,3]\n",
    "        t   (np array): estimated translation vectors [3,1]\n",
    "    Returns:\n",
    "        x1_t (np array): points of the transformed point clouds [n,3]\n",
    "    \"\"\"\n",
    "    x1_t = (np.matmul(R, x1.transpose()) + t).transpose()\n",
    "\n",
    "    return x1_t\n",
    "\n",
    "def sorted_alphanum(file_list_ordered):\n",
    "    \"\"\"\n",
    "    Sorts the list alphanumerically\n",
    "    Args:\n",
    "        file_list_ordered (list): list of files to be sorted\n",
    "    Return:\n",
    "        sorted_list (list): input list sorted alphanumerically\n",
    "    \"\"\"\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "\n",
    "    def alphanum_key(key):\n",
    "        return [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "\n",
    "    sorted_list = sorted(file_list_ordered, key=alphanum_key)\n",
    "\n",
    "    return sorted_list\n",
    "\n",
    "def get_file_list(path, extension=None):\n",
    "    \"\"\"\n",
    "    Build a list of all the files in the provided path\n",
    "    Args:\n",
    "        path (str): path to the directory \n",
    "        extension (str): only return files with this extension\n",
    "    Return:\n",
    "        file_list (list): list of all the files (with the provided extension) sorted alphanumerically\n",
    "    \"\"\"\n",
    "    if extension is None:\n",
    "        file_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    else:\n",
    "        file_list = [\n",
    "            os.path.join(path, f)\n",
    "            for f in os.listdir(path)\n",
    "            if os.path.isfile(os.path.join(path, f)) and os.path.splitext(f)[1] == extension\n",
    "        ]\n",
    "    file_list = sorted_alphanum(file_list)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def get_folder_list(path):\n",
    "    \"\"\"\n",
    "    Build a list of all the folders in the provided path\n",
    "    Args:\n",
    "        path (str): path to the directory \n",
    "    Returns:\n",
    "        folder_list (list): list of all the folders sorted alphanumerically\n",
    "    \"\"\"\n",
    "    folder_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    folder_list = sorted_alphanum(folder_list)\n",
    "    \n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bccaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_consecutive_point_cloud(pc_s, pc_t):\n",
    "    pcd_s = o3d.geometry.PointCloud()\n",
    "    pcd_s.points = o3d.utility.Vector3dVector(pc_s[:, 0:3])\n",
    "    pcd_s.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "    pcd_t = o3d.geometry.PointCloud()\n",
    "    pcd_t.points = o3d.utility.Vector3dVector(pc_t[:, 0:3])\n",
    "    pcd_t.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "    o3d.visualization.draw_geometries([pcd_s, pcd_t])\n",
    "    \n",
    "def plot_correspondences(X,Y):\n",
    "\n",
    "    # X -> N x 3 numpy array of points\n",
    "    # Y -> N x 3 numpy array of points\n",
    "\n",
    "    points = np.concatenate((X,Y),axis=0)\n",
    "    lines = []\n",
    "    for i in range(X.shape[0]):\n",
    "        # lines.append([X.shape[0]])\n",
    "        lines.append([i, i+X.shape[0]])\n",
    "    lines = np.asarray(lines)\n",
    "    colors = [[173/255, 255/255, 47/255] for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet()  \n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    X_pcd = o3d.geometry.PointCloud()\n",
    "    X_pcd.points = o3d.utility.Vector3dVector(X)\n",
    "\n",
    "    Y_pcd = o3d.geometry.PointCloud()\n",
    "    Y_pcd.points = o3d.utility.Vector3dVector(Y)\n",
    "\n",
    "    X_pcd.paint_uniform_color([113/255, 121/255, 126/255])\n",
    "    Y_pcd.paint_uniform_color([196/255, 30/255, 58/255])\n",
    "\n",
    "    o3d.visualization.draw_geometries([X_pcd,Y_pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a846b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation_result(pc, Rt):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc.reshape(-1, 3))\n",
    "    pcd.transform(Rt)\n",
    "    \n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def get_transformation_ransac(data,features,frame):\n",
    "\n",
    "    data_x = data[0]\n",
    "    data_y = data[1]\n",
    "    feature_x = features[0]\n",
    "    feature_y = features[1]\n",
    "\n",
    "#     plot_consecutive_point_cloud(data_x, data_y)\n",
    "    \n",
    "    x_r, x_theta, x_phi = cs.cart2sp(data_x[:,0], data_x[:,1], data_x[:,2])\n",
    "    y_r, y_theta, y_phi = cs.cart2sp(data_y[:,0], data_y[:,1], data_y[:,2])\n",
    "\n",
    "    data_x_p, feature_x_p = kitti_utils.partition(data_x, feature_x, x_theta, x_phi)\n",
    "    data_y_p, feature_y_p = kitti_utils.partition(data_y, feature_y, y_theta, y_phi)\n",
    "    \n",
    "    data_x_c = np.array([])\n",
    "    data_y_c = np.array([])\n",
    "\n",
    "    for i in range(0, int(len(data_x_p)/1)):\n",
    "        if(feature_y_p[i].shape[0] < 2 or feature_x_p[i].shape[0] < 2):\n",
    "            continue\n",
    "        else:\n",
    "            if data_x_c.shape[0] == 0:\n",
    "                distances = sklearn.metrics.pairwise.euclidean_distances(feature_y_p[i],feature_x_p[i])\n",
    "                pred = np.argmin(distances,axis=0)\n",
    "                data_x_c_i = data_x_p[i]\n",
    "                data_y_c_i = data_y_p[i]\n",
    "                a = int(data_x_c_i.shape[0]/2)\n",
    "                b = int(data_x_c_i.shape[0]/4)\n",
    "                \n",
    "                dist_sort = np.sort(distances,axis=0)\n",
    "                dist_ratio = dist_sort[0,:]/dist_sort[1,:]\n",
    "                min_dist = np.min(distances,axis=0)\n",
    "                ordered = np.argsort(min_dist)\n",
    "\n",
    "                pred = pred[ordered[:a]]\n",
    "                data_x_c_i = data_x_c_i[ordered[:a]]\n",
    "                dist_ratio = dist_ratio[ordered[:a]]\n",
    "\n",
    "                dist_ratio_ord = np.argsort(dist_ratio)\n",
    "                pred = pred[dist_ratio_ord[:b]]\n",
    "                data_x_c = data_x_c_i[dist_ratio_ord[:b]]\n",
    "\n",
    "                sort = []\n",
    "                for i in range(b):\n",
    "                    sort.append(data_y_c_i[pred[i]])\n",
    "                data_y_c = np.array(sort)\n",
    "            else:\n",
    "                distances = sklearn.metrics.pairwise.euclidean_distances(feature_y_p[i],feature_x_p[i])\n",
    "                pred = np.argmin(distances,axis=0)\n",
    "                data_x_c_i = data_x_p[i]\n",
    "                data_y_c_i = data_y_p[i]\n",
    "                a = int(data_x_c_i.shape[0]/2)\n",
    "                b = int(data_x_c_i.shape[0]/4)\n",
    "                \n",
    "                dist_sort = np.sort(distances,axis=0)\n",
    "                dist_ratio = dist_sort[0,:]/dist_sort[1,:]\n",
    "                min_dist = np.min(distances,axis=0)\n",
    "                ordered = np.argsort(min_dist)\n",
    "\n",
    "                pred = pred[ordered[:a]]\n",
    "                data_x_c_i = data_x_c_i[ordered[:a]]\n",
    "                dist_ratio = dist_ratio[ordered[:a]]\n",
    "\n",
    "                dist_ratio_ord = np.argsort(dist_ratio)\n",
    "                pred = pred[dist_ratio_ord[:b]]\n",
    "                data_x_c_j = data_x_c_i[dist_ratio_ord[:b]]\n",
    "\n",
    "                sort = []\n",
    "                for i in range(b):\n",
    "                    sort.append(data_y_c_i[pred[i]])\n",
    "                data_y_c_j = np.array(sort)\n",
    "                \n",
    "                if data_x_c_j.shape[0] != 0 and data_y_c_j.shape[0] != 0:\n",
    "                    data_x_c = np.concatenate((data_x_c,data_x_c_j), axis=0)\n",
    "                    data_y_c = np.concatenate((data_y_c,data_y_c_j), axis=0)\n",
    "\n",
    "    x_r, x_theta, x_phi = cs.cart2sp(data_x_c[:,0], data_x_c[:,1], data_x_c[:,2])\n",
    "    y_r, y_theta, y_phi = cs.cart2sp(data_y_c[:,0], data_y_c[:,1], data_y_c[:,2])\n",
    "\n",
    "    x_phi = x_phi * 180/np.pi\n",
    "    y_phi = y_phi * 180/np.pi\n",
    "\n",
    "    diff_phi = np.abs(x_phi-y_phi)\n",
    "    diff_r = np.abs(x_r-y_r)\n",
    "    data_x_c = data_x_c[np.logical_and(diff_phi<3.5,diff_r<4)]   #3.5  4\n",
    "    data_y_c = data_y_c[np.logical_and(diff_phi<3.5,diff_r<4)]\n",
    "\n",
    "#     data_x_c_aug = np.concatenate((data_x_c, np.ones((data_x_c.shape[0],1))),axis=1)\n",
    "#     data_y_c_aug = np.concatenate((data_y_c, np.ones((data_y_c.shape[0],1))),axis=1)\n",
    "\n",
    "#     l_x = (lidar_to_cam @ data_x_c_aug.T).T\n",
    "#     l_y = (lidar_to_cam @ data_y_c_aug.T).T\n",
    "\n",
    "#     data_x_c = l_x[:,:3]\n",
    "#     data_y_c = l_y[:,:3]\n",
    "#     plot_correspondences(data_x_c, data_y_c)\n",
    "    \n",
    "    '''\n",
    "    distances = sklearn.metrics.pairwise.euclidean_distances(feature_y,feature_x)\n",
    "    pred = np.argmin(distances, axis=0)\n",
    "    \n",
    "    dist_sort = np.sort(distances,axis=0)\n",
    "    dist_ratio = dist_sort[0,:]/dist_sort[1,:]\n",
    "    min_dist = np.min(distances,axis=0)\n",
    "    ordered = np.argsort(min_dist)\n",
    "    \n",
    "    pred = pred[ordered[:1024]]\n",
    "    data_x = data_x[ordered[:1024]]\n",
    "    dist_ratio = dist_ratio[ordered[:1024]]\n",
    "\n",
    "    dist_ratio_ord = np.argsort(dist_ratio)\n",
    "    pred = pred[dist_ratio_ord[:32]]\n",
    "    data_x_c = data_x[dist_ratio_ord[:32]]\n",
    "\n",
    "    sort = []\n",
    "    for i in range(32):\n",
    "        sort.append(data_y[pred[i]])\n",
    "    data_y_c = np.array(sort)\n",
    "    \n",
    "    plot_correspondences(data_x_c, data_y_c)\n",
    "    '''\n",
    "    vec = np.expand_dims(np.arange(data_x_c.shape[0]), 1)\n",
    "    vec = np.concatenate((vec,vec),axis=1)\n",
    "    vect = o3d.utility.Vector2iVector(vec)\n",
    "\n",
    "    data_x_c1 = o3d.geometry.PointCloud()\n",
    "    data_x_c1.points = o3d.utility.Vector3dVector(data_x_c)\n",
    "\n",
    "    data_y_c1 = o3d.geometry.PointCloud()\n",
    "    data_y_c1.points = o3d.utility.Vector3dVector(data_y_c)\n",
    "\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_correspondence(data_x_c1, data_y_c1, vect, 0.1)\n",
    "\n",
    "    Rt = result.transformation\n",
    "\n",
    "    kitti_utils.log_matrix(frame, Rt, LOG_FOUT)\n",
    "\n",
    "    return Rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b592c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": [
    "folder_list_test = get_folder_list('\\\\Workspace\\\\SceneFlow\\\\datasets\\\\argoverse\\\\val')\n",
    "file_list_test = []\n",
    "\n",
    "for folder in folder_list_test:\n",
    "    file_list = get_file_list(folder)\n",
    "    for file in file_list:\n",
    "        file_list_test.append(file)\n",
    "\n",
    "print(len(file_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2905e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "with open('pointhop.pkl', 'rb') as f:\n",
    "    params = pickle.load(f, encoding='latin')\n",
    "# T_total = np.eye(4)\n",
    "# T_total = np.array([1.000000e+00, 1.197625e-11, 1.704638e-10, 1.665335e-16, 1.197625e-11, 1.000000e+00, 3.562503e-10, -1.110223e-16, 1.704638e-10, 3.562503e-10, 1.000000e+00, 2.220446e-16, 0, 0, 0, 1])\n",
    "# T_total = T_total.reshape(4,4)\n",
    "# kitti_utils.log_matrix(0, T_total, LOG_FOUT)\n",
    "\n",
    "for idx, file in enumerate(file_list_test):\n",
    "    if idx < 32:\n",
    "        continue\n",
    "    pc_data = np.load(file)\n",
    "    data_x = pc_data['pc1']\n",
    "    data_y = pc_data['pc2']\n",
    "    \n",
    "    attribute_0, data_0 = kitti_utils.attribute(data_x)\n",
    "    attribute_1, data_1 = kitti_utils.attribute(data_y)\n",
    "    attribute_h = np.concatenate((attribute_0, attribute_1), axis=0)\n",
    "    data = np.concatenate((data_0, data_1), axis=0)\n",
    "\n",
    "    leaf_node = rpointhop.pointhop_pred(data, attribute_h, pca_params=params, n_sample=[36,8,16])\n",
    "    features = np.moveaxis(np.squeeze(np.asarray(leaf_node)), 0, 2)\n",
    "    Rt = get_transformation_ransac(data, features, idx)\n",
    "    \n",
    "    data_x_w = get_transformation_result(data_x, Rt)\n",
    "    plot_consecutive_point_cloud(data_x_w, data_y)\n",
    "    print(idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026a9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
