{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0148df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\jiahaogu\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyntcloud import PyntCloud\n",
    "import xgboost as xgb\n",
    "import threading\n",
    "# from ai import cs\n",
    "import rpointhop\n",
    "import utils\n",
    "# import kitti_utils\n",
    "# import point_utils\n",
    "# import data_transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ea6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_alphanum(file_list_ordered):\n",
    "    \"\"\"\n",
    "    Sorts the list alphanumerically\n",
    "    Args:\n",
    "        file_list_ordered (list): list of files to be sorted\n",
    "    Return:\n",
    "        sorted_list (list): input list sorted alphanumerically\n",
    "    \"\"\"\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "\n",
    "    def alphanum_key(key):\n",
    "        return [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "\n",
    "    sorted_list = sorted(file_list_ordered, key=alphanum_key)\n",
    "\n",
    "    return sorted_list\n",
    "    \n",
    "def get_file_list(path, extension=None):\n",
    "    \"\"\"\n",
    "    Build a list of all the files in the provided path\n",
    "    Args:\n",
    "        path (str): path to the directory \n",
    "        extension (str): only return files with this extension\n",
    "    Return:\n",
    "        file_list (list): list of all the files (with the provided extension) sorted alphanumerically\n",
    "    \"\"\"\n",
    "    if extension is None:\n",
    "        file_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    else:\n",
    "        file_list = [\n",
    "            os.path.join(path, f)\n",
    "            for f in os.listdir(path)\n",
    "            if os.path.isfile(os.path.join(path, f)) and os.path.splitext(f)[1] == extension\n",
    "        ]\n",
    "    file_list = sorted_alphanum(file_list)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def get_folder_list(path):\n",
    "    \"\"\"\n",
    "    Build a list of all the files in the provided path\n",
    "    Args:\n",
    "        path (str): path to the directory \n",
    "        extension (str): only return files with this extension\n",
    "    Returns:\n",
    "        file_list (list): list of all the files (with the provided extension) sorted alphanumerically\n",
    "    \"\"\"\n",
    "    folder_list = [os.path.join(path, f) for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    folder_list = sorted_alphanum(folder_list)\n",
    "    \n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbe94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_estimation(file_test, xgb_model):\n",
    "    \"\"\"\n",
    "    Generate dynamic labels of the testing dataset\n",
    "    \n",
    "    Args:\n",
    "        file_test (str)\n",
    "        lr (sklearn.linear_model.LogisticRegression)\n",
    "    Returns:\n",
    "        dynamic_label_test (np array): [n,]\n",
    "    \"\"\"\n",
    "    pc_data = np.load(file_test)\n",
    "    eigen_features = pc_data['eigen_features_s'].reshape(-1, 14)\n",
    "    chamfer_dist = pc_data['chamfer_dist'].reshape(-1, 1)\n",
    "    \n",
    "    feature_test = np.concatenate((eigen_features, chamfer_dist), axis=1)\n",
    "    feature_test = feature_test[:, 6:15]\n",
    "    feature_test = feature_test[:, [2, 3, 4, 6, 8]]\n",
    "\n",
    "    dynamic_label_test = xgb_model.predict(feature_test.reshape(-1,5))\n",
    "    \n",
    "    return dynamic_label_test\n",
    "\n",
    "def cluster(file_test, xgb_model, cluster_estimator):\n",
    "    \"\"\"\n",
    "    Divide the dynamic points into different clusters\n",
    "    \n",
    "    Args:\n",
    "        file_test (str)\n",
    "        cluster_estimator (sklearn.cluster.DBSCAN)\n",
    "    Returns:\n",
    "        inst_label (np array): [n,]\n",
    "    \"\"\"\n",
    "    pc_data = np.load(file_test)\n",
    "    pc = pc_data['pc1']\n",
    "    eigen_features = pc_data['eigen_features_s'].reshape(-1, 14)\n",
    "    dynamic_label_test = dynamic_estimation(file_test, xgb_model)\n",
    "    \n",
    "    idx_dynamic = np.where(dynamic_label_test == 1)[0]\n",
    "    fea_dynamic = eigen_features[idx_dynamic, :]\n",
    "    xyz_dynamic = fea_dynamic[:, 0:3]\n",
    "    \n",
    "    if xyz_dynamic.shape[0] != 0:\n",
    "        inst_label_dynamic = cluster_estimator.fit_predict(xyz_dynamic)\n",
    "    \n",
    "    inst_label = np.ones(len(dynamic_label_test)) * -1\n",
    "    for i, idx in enumerate(idx_dynamic):\n",
    "        inst_label[idx] = inst_label_dynamic[i]\n",
    "        \n",
    "    return inst_label\n",
    "    \n",
    "def segment_corresponding_object(pc_s, pc_t, eigen_features_t, length=2):\n",
    "    \"\"\"\n",
    "    Divide the dynamic points into different clusters\n",
    "    \n",
    "    Args:\n",
    "        pc_s (np array): point cloud of a dynamic object\n",
    "        pc_t (np array): point cloud of the next time frame\n",
    "        n_neighbors (int)\n",
    "    Returns:\n",
    "        pc_t_sample (np array): point cloud of the adjacent area of the dynamic object in the next time frame [n, 3]\n",
    "        eigen_features_t_sample (np array)\n",
    "    \"\"\"\n",
    "    idx_knn = np.array([])\n",
    "    \n",
    "    # for i in range(len(pc_s)):\n",
    "        # pt = pc_s[i].reshape(1,3)\n",
    "        # pc = np.concatenate((pt, pc_t))\n",
    "        \n",
    "        # pcd = o3d.geometry.PointCloud()\n",
    "        # pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "        # start = time.time()\n",
    "        # pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "        # [k, nn_idx, _] = pcd_tree.search_knn_vector_3d(pcd.points[0], n_neighbors)\n",
    "        # end = time.time()\n",
    "        # print(end - start)\n",
    "        \n",
    "        # nn_idx = np.asarray(nn_idx[1:])\n",
    "        # nn_idx = nn_idx - 1\n",
    "        \n",
    "        # idx_knn = np.append(idx_knn, nn_idx)\n",
    "    \n",
    "    # idx_knn = np.unique(idx_knn).astype(int)\n",
    "    \n",
    "    xyz_max = pc_s.max(axis=0)\n",
    "    xyz_min = pc_s.min(axis=0)\n",
    "    \n",
    "    idx_knn = np.where((pc_t[:,0] > xyz_min[0] - length) & (pc_t[:,0] < xyz_max[0] + length) & \n",
    "                       (pc_t[:,1] > xyz_min[1] - length) & (pc_t[:,1] < xyz_max[1] + length) & \n",
    "                       (pc_t[:,2] > xyz_min[2] - length) & (pc_t[:,2] < xyz_max[2] + length))[0]\n",
    "    \n",
    "    pc_t_sample = pc_t[idx_knn, :]\n",
    "    eigen_features_t_sample = eigen_features_t[idx_knn, :]\n",
    "    \n",
    "    return pc_t_sample, eigen_features_t_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f23e8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation_result(pc, Rt):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc.reshape(-1, 3))\n",
    "    pcd.transform(Rt)\n",
    "    \n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def get_transformation_ransac(data_x, data_y, feature_x, feature_y):\n",
    "    distances = sklearn.metrics.pairwise.euclidean_distances(feature_y,feature_x)\n",
    "    pred = np.argmin(distances, axis=0)\n",
    "    \n",
    "    dist_sort = np.sort(distances,axis=0)\n",
    "    dist_ratio = dist_sort[0,:]/dist_sort[1,:]\n",
    "    min_dist = np.min(distances,axis=0)\n",
    "    ordered = np.argsort(min_dist)\n",
    "    \n",
    "    if ordered.shape[0] > 384:\n",
    "        pred = pred[ordered[:384]]\n",
    "        data_x = data_x[ordered[:384]]\n",
    "        dist_ratio = dist_ratio[ordered[:384]]\n",
    "\n",
    "        dist_ratio_ord = np.argsort(dist_ratio)\n",
    "        pred = pred[dist_ratio_ord[:256]]\n",
    "        data_x_c = data_x[dist_ratio_ord[:256]]\n",
    "\n",
    "        sort = []\n",
    "        for i in range(256):\n",
    "            sort.append(data_y[pred[i]])\n",
    "        data_y_c = np.array(sort)\n",
    "    else:\n",
    "        pred = pred[ordered[:64]]\n",
    "        data_x = data_x[ordered[:64]]\n",
    "        dist_ratio = dist_ratio[ordered[:64]]\n",
    "\n",
    "        dist_ratio_ord = np.argsort(dist_ratio)\n",
    "        pred = pred[dist_ratio_ord[:32]]\n",
    "        data_x_c = data_x[dist_ratio_ord[:32]]\n",
    "\n",
    "        sort = []\n",
    "        for i in range(32):\n",
    "            sort.append(data_y[pred[i]])\n",
    "        data_y_c = np.array(sort)\n",
    "    \n",
    "#     plot_correspondences(data_x_c, data_y_c)\n",
    "    \n",
    "    vec = np.expand_dims(np.arange(data_x_c.shape[0]), 1)\n",
    "    vec = np.concatenate((vec,vec), axis=1)\n",
    "    vect = o3d.utility.Vector2iVector(vec)\n",
    "    \n",
    "    data_x_c1 = o3d.geometry.PointCloud()\n",
    "    data_x_c1.points = o3d.utility.Vector3dVector(data_x_c)\n",
    "\n",
    "    data_y_c1 = o3d.geometry.PointCloud()\n",
    "    data_y_c1.points = o3d.utility.Vector3dVector(data_y_c)\n",
    "    \n",
    "    estimation_method = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    criteria = o3d.pipelines.registration.RANSACConvergenceCriteria()\n",
    "    criteria.max_iteration = 100000\n",
    "    criteria.confidence = 0.999\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_correspondence(data_x_c1, data_y_c1, vect, 0.1, \n",
    "                                                                                    estimation_method=estimation_method, \n",
    "                                                                                    ransac_n=3, \n",
    "                                                                                    criteria=criteria)\n",
    "    \n",
    "    Rt = result.transformation\n",
    "    \n",
    "    data_x_w = get_transformation_result(data_x, Rt)\n",
    "    \n",
    "#     R = Rt[0:3, 0:3]\n",
    "#     t = np.transpose(Rt[0:3, 3])\n",
    "#     data_x_w = data_x @ R + t\n",
    "    \n",
    "#     plot_consecutive_point_cloud(data_x_w, data_y)\n",
    "    \n",
    "    '''\n",
    "    x_mean = np.mean(data_x_c,axis=0,keepdims=True)\n",
    "    y_mean = np.mean(data_y_c,axis=0,keepdims=True)\n",
    "\n",
    "    data_x_c = data_x_c - x_mean\n",
    "    data_y_c = data_y_c - y_mean\n",
    "\n",
    "    cov = (data_y_c.T@data_x_c)\n",
    "    u, s, v = np.linalg.svd(cov)\n",
    "    R = v.T@u.T\n",
    "\n",
    "    if (np.linalg.det(R) < 0):\n",
    "        u, s, v = np.linalg.svd(cov)\n",
    "        reflect = np.eye(3)\n",
    "        reflect[2,2] = -1\n",
    "        v = v.T@reflect\n",
    "        R = v@u.T\n",
    "\n",
    "    t = -R@y_mean.T+x_mean.T\n",
    "\n",
    "    Rt = np.concatenate((R.T, -t),axis=1)\n",
    "    ones = np.zeros((1,4))\n",
    "    ones[0,3] = 1\n",
    "    Rt = np.concatenate((Rt, ones),axis=0)\n",
    "    \n",
    "    data_x_w = get_transformation_result(data_x, Rt)\n",
    "    \n",
    "#     plot_consecutive_point_cloud(data_x_w, data_y)\n",
    "    '''\n",
    "    return Rt\n",
    "\n",
    "def read_feature(eigen_features):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(eigen_features[:,:3])  \n",
    "    pointcloud = PyntCloud.from_instance(\"open3d\", pcd)\n",
    "    neighbors = pointcloud.get_neighbors(k=48)\n",
    "    \n",
    "    pts_fea_expand = utils.index_points(np.expand_dims(eigen_features, axis=0), np.expand_dims(neighbors, axis=0))\n",
    "    pts = pts_fea_expand[..., :3]\n",
    "    eig = pts_fea_expand[..., 6:]\n",
    "    return np.expand_dims(pts[0], axis=0), np.expand_dims(eig[0], axis=0)\n",
    "\n",
    "def calc_feature(pc_temp, pc_bin, pc_gather):\n",
    "    value = np.multiply(pc_temp, pc_bin)\n",
    "    value = np.sum(value, axis=2, keepdims=True)\n",
    "    num = np.sum(pc_bin, axis=2, keepdims=True)\n",
    "    final = np.squeeze(value / num, axis=(2, ))\n",
    "    pc_gather.append(final)\n",
    "    \n",
    "def attribute(eigen_features): \n",
    "    pc_n, pc_temp = read_feature(eigen_features)\n",
    "    pc_n_center = np.expand_dims(pc_n[:, :, 0, :], axis=2)\n",
    "    pc_n_uncentered = pc_n - pc_n_center\n",
    "    pc_temp = np.concatenate((pc_temp,pc_n_uncentered),axis=-1)\n",
    "\n",
    "    pc_idx = []\n",
    "    pc_idx.append(pc_n_uncentered[:, :, :, 0] >= 0)\n",
    "    pc_idx.append(pc_n_uncentered[:, :, :, 0] <= 0)\n",
    "    pc_idx.append(pc_n_uncentered[:, :, :, 1] >= 0)\n",
    "    pc_idx.append(pc_n_uncentered[:, :, :, 1] <= 0)\n",
    "    pc_idx.append(pc_n_uncentered[:, :, :, 2] >= 0)\n",
    "    pc_idx.append(pc_n_uncentered[:, :, :, 2] <= 0)\n",
    "\n",
    "    pc_bin = []\n",
    "    pc_bin.append(np.expand_dims((pc_idx[0] * pc_idx[2] * pc_idx[4]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[0] * pc_idx[2] * pc_idx[5]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[0] * pc_idx[3] * pc_idx[4]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[0] * pc_idx[3] * pc_idx[5]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[1] * pc_idx[2] * pc_idx[4]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[1] * pc_idx[2] * pc_idx[5]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[1] * pc_idx[3] * pc_idx[4]) * 1.0, axis=3))\n",
    "    pc_bin.append(np.expand_dims((pc_idx[1] * pc_idx[3] * pc_idx[5]) * 1.0, axis=3))\n",
    "\n",
    "    pc_gather1 = []\n",
    "    pc_gather2 = []\n",
    "    pc_gather3 = []\n",
    "    pc_gather4 = []\n",
    "    pc_gather5 = []\n",
    "    pc_gather6 = []\n",
    "    pc_gather7 = []\n",
    "    pc_gather8 = []\n",
    "    threads = []\n",
    "    t1 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[0], pc_gather1))\n",
    "    threads.append(t1)\n",
    "    t2 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[1], pc_gather2))\n",
    "    threads.append(t2)\n",
    "    t3 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[2], pc_gather3))\n",
    "    threads.append(t3)\n",
    "    t4 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[3], pc_gather4))\n",
    "    threads.append(t4)\n",
    "    t5 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[4], pc_gather5))\n",
    "    threads.append(t5)\n",
    "    t6 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[5], pc_gather6))\n",
    "    threads.append(t6)\n",
    "    t7 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[6], pc_gather7))\n",
    "    threads.append(t7)\n",
    "    t8 = threading.Thread(target=calc_feature, args=(pc_temp, pc_bin[7], pc_gather8))\n",
    "    threads.append(t8)\n",
    "    for t in threads:\n",
    "        t.setDaemon(False)\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        # if t.isAlive():\n",
    "        t.join()\n",
    "    pc_gather = pc_gather1 + pc_gather2 + pc_gather3 + pc_gather4 + pc_gather5 + pc_gather6 + pc_gather7 + pc_gather8\n",
    "\n",
    "    pc_fea = np.concatenate(pc_gather, axis=2)\n",
    "\n",
    "    return pc_fea\n",
    "\n",
    "def furthest_point_sample(pts, K):\n",
    "    # pts = np.expand_dims(pts, axis=0)\n",
    "    B, N, C = pts.shape\n",
    "    centroids = np.zeros((B, K), dtype=int)\n",
    "    distance = np.ones((B, N), dtype=int) * 1e10\n",
    "    np.random.seed(0)\n",
    "    farthest = np.random.randint(0, N, (B,))\n",
    "    # farthest = np.array([0,0])\n",
    "    batch_indices = np.arange(B)\n",
    "    for i in range(K):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = pts[batch_indices, farthest, :].reshape(B, 1, 3)\n",
    "        dist = np.sum((pts - centroid) ** 2, axis=-1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = np.argmax(distance, axis=-1)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def generate_transformation_matrix(pc_s, pc_t, attribute_s, attribute_t, params):\n",
    "#     plot_consecutive_point_cloud(pc_s, pc_t)\n",
    "#     pt_num = min(pc_s.shape[0], pc_t.shape[0])\n",
    "#     if pt_num > 1024:\n",
    "#         index_s = np.squeeze(furthest_point_sample(np.expand_dims(pc_s, axis=0), 1024))\n",
    "#         index_t = np.squeeze(furthest_point_sample(np.expand_dims(pc_t, axis=0), 1024))\n",
    "#         pc_s = pc_s[index_s, :]\n",
    "#         pc_t = pc_t[index_t, :]\n",
    "#         eigen_features_s = eigen_features_s[index_s, :]\n",
    "#         eigen_features_t = eigen_features_t[index_t, :]\n",
    "#     else:\n",
    "#         if pc_s.shape[0] == pt_num:\n",
    "#             index_t = np.squeeze(furthest_point_sample(np.expand_dims(pc_t, axis=0), pt_num))\n",
    "#             pc_t = pc_t[index_t, :]\n",
    "#             eigen_features_t = eigen_features_t[index_t, :]\n",
    "#         else:\n",
    "#             index_s = np.squeeze(furthest_point_sample(np.expand_dims(pc_s, axis=0), pt_num))\n",
    "#             pc_s = pc_s[index_s, :]\n",
    "#             eigen_features_s = eigen_features_s[index_s, :]\n",
    "        \n",
    "#     plot_consecutive_point_cloud(pc_s, pc_t)\n",
    "    \n",
    "    pc_s = np.expand_dims(pc_s, axis=0)\n",
    "    pc_t = np.expand_dims(pc_t, axis=0)\n",
    "#     attribute_s = attribute(eigen_features_s)\n",
    "#     attribute_t = attribute(eigen_features_t)\n",
    "    \n",
    "#     pc_data = np.concatenate((pc_s, pc_t), axis=0)\n",
    "#     attribute_h = np.concatenate((attribute_s, attribute_t), axis=0)\n",
    "    \n",
    "#     leaf_node = rpointhop.pointhop_pred(pc_data, attribute_h, pca_params=params, n_sample=[36,8,16])\n",
    "#     features = np.moveaxis(np.squeeze(np.asarray(leaf_node)), 0, 2)\n",
    "    \n",
    "#     data_x = pc_data[0]\n",
    "#     data_y = pc_data[1]\n",
    "#     feature_x = features[0]\n",
    "#     feature_y = features[1]\n",
    "    \n",
    "    data_x = pc_s[0]\n",
    "    data_y = pc_t[0]\n",
    "    \n",
    "    leaf_node_x = rpointhop.pointhop_pred(data_x, attribute_s, pca_params=params, n_sample=[36,8,16])\n",
    "    feature_x = np.moveaxis(np.squeeze(np.asarray(leaf_node_x)), 0, 1)\n",
    "    leaf_node_y = rpointhop.pointhop_pred(data_y, attribute_t, pca_params=params, n_sample=[36,8,16])\n",
    "    feature_y = np.moveaxis(np.squeeze(np.asarray(leaf_node_y)), 0, 1)\n",
    "    \n",
    "    T_total = get_transformation_ransac(data_x, data_y, feature_x, feature_y)\n",
    "    \n",
    "    return T_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940c0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correspondences(X,Y):\n",
    "\n",
    "    # X -> N x 3 numpy array of points\n",
    "    # Y -> N x 3 numpy array of points\n",
    "\n",
    "    points = np.concatenate((X,Y),axis=0)\n",
    "    lines = []\n",
    "    for i in range(X.shape[0]):\n",
    "        # lines.append([X.shape[0]])\n",
    "        lines.append([i, i+X.shape[0]])\n",
    "    lines = np.asarray(lines)\n",
    "    colors = [[173/255, 255/255, 47/255] for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet()  \n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    X_pcd = o3d.geometry.PointCloud()\n",
    "    X_pcd.points = o3d.utility.Vector3dVector(X)\n",
    "\n",
    "    Y_pcd = o3d.geometry.PointCloud()\n",
    "    Y_pcd.points = o3d.utility.Vector3dVector(Y)\n",
    "\n",
    "    X_pcd.paint_uniform_color([113/255, 121/255, 126/255])\n",
    "    Y_pcd.paint_uniform_color([196/255, 30/255, 58/255])\n",
    "\n",
    "    o3d.visualization.draw_geometries([X_pcd,Y_pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb65d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moving_objects(pts, sem_label, inst_label):\n",
    "    moving_idx_s = np.where(sem_label >= 0)[0]\n",
    "    static_idx_s = np.where(sem_label < 0)[0]\n",
    "    \n",
    "    # Filter out the points and labels\n",
    "    moving_sem_label = sem_label[moving_idx_s]\n",
    "    moving_inst_label = inst_label[moving_idx_s]\n",
    "    moving_pts = pts[moving_idx_s, :]\n",
    "    static_pts = pts[static_idx_s, :]\n",
    "    \n",
    "    # Unique semantic labels\n",
    "    unique_moving_labels = np.unique(moving_sem_label)\n",
    "    \n",
    "    pcd = []\n",
    "    # Plot static objects\n",
    "    static_pcd = o3d.geometry.PointCloud()\n",
    "    static_pcd.points = o3d.utility.Vector3dVector(static_pts[:, 0:3])\n",
    "    static_pcd.paint_uniform_color([220/255, 220/255, 220/255])\n",
    "    pcd.append(static_pcd)\n",
    "    \n",
    "    # Plot moving objects\n",
    "    for label in unique_moving_labels:\n",
    "        class_idx = np.where(moving_sem_label == label)[0]\n",
    "        class_instances = moving_inst_label[class_idx]\n",
    "        class_points = moving_pts[class_idx, 0:3]\n",
    "        tmp_instances = np.unique(class_instances)\n",
    "\n",
    "        for instance in tmp_instances:\n",
    "            object_idx = np.where(class_instances == instance)[0]\n",
    "            object_points = class_points[object_idx, 0:3].reshape(-1, 3)\n",
    "        \n",
    "            # Save the points and sample a random color\n",
    "            object_pcd = o3d.geometry.PointCloud()\n",
    "            object_color = np.repeat(np.random.random(size=3).reshape(1, -1), repeats=object_points.shape[0], axis=0)\n",
    "            object_pcd.points = o3d.utility.Vector3dVector(object_points)\n",
    "            object_pcd.colors = o3d.utility.Vector3dVector(object_color)\n",
    "            pcd.append(object_pcd)\n",
    "    \n",
    "    o3d.visualization.draw_geometries(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276471f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_consecutive_point_cloud(pc_s, pc_t):\n",
    "    pcd_s = o3d.geometry.PointCloud()\n",
    "    pcd_s.points = o3d.utility.Vector3dVector(pc_s[:, 0:3])\n",
    "    pcd_s.paint_uniform_color([1, 0, 0])\n",
    "\n",
    "    pcd_t = o3d.geometry.PointCloud()\n",
    "    pcd_t.points = o3d.utility.Vector3dVector(pc_t[:, 0:3])\n",
    "    pcd_t.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "    o3d.visualization.draw_geometries([pcd_s, pcd_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8e95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst_label_refine(pc, inst_label):\n",
    "    inst_label_new = np.array(inst_label)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    inst_label_unique = np.unique(inst_label)\n",
    "    for label in inst_label_unique:\n",
    "        if label == -1:\n",
    "            continue\n",
    "        moving_object_idx = np.where(inst_label == label)[0]\n",
    "        moving_object_idx_queue = moving_object_idx.tolist()\n",
    "\n",
    "        moving_object_pt = pc[moving_object_idx, :]\n",
    "        moving_object_mean = np.mean(moving_object_pt, axis=0)\n",
    "\n",
    "        while moving_object_idx_queue:\n",
    "            pt_idx = moving_object_idx_queue.pop(0)\n",
    "            [k, nn_idx, _] = pcd_tree.search_knn_vector_3d(pcd.points[pt_idx], 32)\n",
    "            for idx in nn_idx:\n",
    "                if np.linalg.norm(pc[pt_idx] - pc[idx]) < 1.5:\n",
    "                    if inst_label_new[idx] != label:\n",
    "                        dist = np.linalg.norm(moving_object_mean - pc[idx])\n",
    "                        if dist < 6.48:\n",
    "                            inst_label_new[idx] = label\n",
    "                            moving_object_idx_queue.append(idx)\n",
    "    \n",
    "    return inst_label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3b6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst_label_refine2(pc, inst_label, inst_label_new):\n",
    "    inst_label_new_new = np.array(inst_label)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pc)\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    inst_label_unique = np.unique(inst_label_new)\n",
    "    inliers_all = np.zeros(pc.shape[0])\n",
    "    for label in inst_label_unique:\n",
    "        if label == -1:\n",
    "            continue\n",
    "        moving_object_idx = np.where(inst_label_new == label)[0]\n",
    "        moving_object_pt = pc[moving_object_idx, :]\n",
    "        \n",
    "        moving_object_pt_height = moving_object_pt[:, 1]\n",
    "        moving_object_pt_height_min = moving_object_pt_height.min()\n",
    "        ground_idx = np.where(moving_object_pt_height < moving_object_pt_height_min + 0.5)[0]\n",
    "        moving_object_ground_pt = moving_object_pt[ground_idx, :]\n",
    "        moving_object_idx = moving_object_idx[ground_idx]\n",
    "        \n",
    "        pcd_moving_object = o3d.geometry.PointCloud()\n",
    "        pcd_moving_object.points = o3d.utility.Vector3dVector(moving_object_ground_pt[:, 0:3])\n",
    "#         pcd_moving_object.paint_uniform_color([0, 0, 1])\n",
    "#         o3d.visualization.draw_geometries([pcd_moving_object])\n",
    "        \n",
    "        if moving_object_ground_pt.shape[0] < 64:\n",
    "            continue\n",
    "\n",
    "        plane_model, inliers = pcd_moving_object.segment_plane(distance_threshold=0.0575,\n",
    "                                                               ransac_n=3,\n",
    "                                                               num_iterations=1000)\n",
    "        \n",
    "#         inlier_cloud = pcd_moving_object.select_by_index(inliers)\n",
    "#         inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "#         outlier_cloud = pcd_moving_object.select_by_index(inliers, invert=True)\n",
    "#         inlier_cloud.paint_uniform_color([0, 0, 1.0])\n",
    "#         o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])\n",
    "        \n",
    "        inliers = np.array(inliers)\n",
    "        inliers_idx = moving_object_idx[inliers]\n",
    "        inliers_all[inliers_idx] = 1\n",
    "\n",
    "#     plot_moving_objects(pc, inliers_all, inliers_all)\n",
    "    inliers_idx_all = np.where(inliers_all == 1)[0]\n",
    "    inst_label_new_new[inliers_idx_all] = -1\n",
    "    \n",
    "    # Recluster\n",
    "    idx_dynamic = np.where(inst_label_new_new > -1)[0]\n",
    "    xyz_dynamic = pc[idx_dynamic, 0:3]\n",
    "    \n",
    "    if xyz_dynamic.shape[0] != 0:\n",
    "        inst_label_dynamic = cluster_estimator.fit_predict(xyz_dynamic)\n",
    "    \n",
    "    inst_label_new_new2 = np.ones(pc.shape[0]) * -1\n",
    "    for i, idx in enumerate(idx_dynamic):\n",
    "        inst_label_new_new2[idx] = inst_label_dynamic[i]\n",
    "    \n",
    "        \n",
    "    inst_label_unique = np.unique(inst_label_new_new2)\n",
    "    for label in inst_label_unique:\n",
    "        if label == -1:\n",
    "            continue\n",
    "        moving_object_idx = np.where(inst_label_new_new2 == label)[0]\n",
    "        moving_object_idx_queue = moving_object_idx.tolist()\n",
    "\n",
    "        moving_object_pt = pc[moving_object_idx, :]\n",
    "        if moving_object_pt.shape[0] == 0:\n",
    "            continue\n",
    "        moving_object_mean = np.mean(moving_object_pt, axis=0)\n",
    "\n",
    "        while moving_object_idx_queue:\n",
    "            pt_idx = moving_object_idx_queue.pop(0)\n",
    "            [k, nn_idx, _] = pcd_tree.search_knn_vector_3d(pcd.points[pt_idx], 32)\n",
    "            for idx in nn_idx:\n",
    "                if inliers_all[idx] != 1:\n",
    "                    if np.linalg.norm(pc[pt_idx] - pc[idx]) < 1.5:\n",
    "                        if inst_label_new_new2[idx] != label:\n",
    "                            dist = np.linalg.norm(moving_object_mean - pc[idx])\n",
    "                            if dist < 6.38:\n",
    "                                inst_label_new_new2[idx] = label\n",
    "                                moving_object_idx_queue.append(idx)\n",
    "    \n",
    "    return inst_label_new_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "827489cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model('\\\\Workspace\\\\SceneFlow\\\\configs\\\\classifier4.json')\n",
    "cluster_estimator = DBSCAN(eps=1.5)\n",
    "\n",
    "# folder_list_test = get_folder_list('\\\\Workspace\\\\SceneFlow\\\\save\\\\testing_dataset')\n",
    "file_list_test = []\n",
    "\n",
    "# for folder in folder_list_test:\n",
    "#     file_list = get_file_list(folder)\n",
    "#     for file in file_list:\n",
    "#         file_list_test.append(file)\n",
    "\n",
    "file_list = get_file_list('\\\\Workspace\\\\SceneFlow\\\\datasets\\\\stereoKITTI_dynamic_estimation')\n",
    "for file in file_list:\n",
    "    file_list_test.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4f894be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "with open('pointhop.pkl', 'rb') as f:\n",
    "    pointhop = pickle.load(f, encoding='latin')\n",
    "\n",
    "for j, file in enumerate(file_list_test):\n",
    "#     if j < 51:\n",
    "#         continue\n",
    "    pc_data = np.load(file)\n",
    "    pc_s = pc_data['pc1']\n",
    "    pc_t = pc_data['pc2']\n",
    "    eigen_features_s = pc_data['eigen_features_s']\n",
    "    eigen_features_t = pc_data['eigen_features_t']\n",
    "    flow_gt = pc_data['flow_gt']\n",
    "    flow_estimate = pc_data['flow_estimate']\n",
    "    pc_s_s = pc_s - flow_estimate\n",
    "#     pc_s[:, [1, 2]] = pc_s[:, [2, 1]]\n",
    "#     pc_t[:, [1, 2]] = pc_t[:, [2, 1]]\n",
    "    \n",
    "    attribute_s = attribute(eigen_features_s)\n",
    "    attribute_t = attribute(eigen_features_t)\n",
    "    attribute_s = np.squeeze(attribute_s)\n",
    "    attribute_t = np.squeeze(attribute_t)\n",
    "    \n",
    "    pc_s_w = np.array(pc_s)\n",
    "    inst_label = cluster(file, xgb_model, cluster_estimator)\n",
    "    inst_label_new = inst_label_refine(pc_s, inst_label)\n",
    "    \n",
    "    inst_label_new_new = inst_label_refine2(pc_s, inst_label, inst_label_new)\n",
    "    \n",
    "#     plot_moving_objects(pc_s, inst_label_new_new, inst_label_new_new)\n",
    "        \n",
    "    inst_label_unique = np.unique(inst_label_new_new)\n",
    "    T_total = np.ndarray((int(inst_label_unique.max() + 1), 4, 4))\n",
    "    for i in inst_label_unique:\n",
    "        if i == -1:\n",
    "            continue\n",
    "        else:\n",
    "            idx_i = np.where(inst_label_new_new == i)[0]\n",
    "            pc_s_i = pc_s[idx_i, :]\n",
    "            attribute_s_i = attribute_s[idx_i, :]\n",
    "            \n",
    "            pc_t_i, attribute_t_i = segment_corresponding_object(pc_s_i, pc_t, attribute_t, length=1)\n",
    "            \n",
    "#             ground_segmentation(pc_s_i)\n",
    "            \n",
    "            attribute_s_i = np.expand_dims(attribute_s_i, axis=0)\n",
    "            attribute_t_i = np.expand_dims(attribute_t_i, axis=0)\n",
    "            \n",
    "#             plot_consecutive_point_cloud(pc_s_i, pc_t_i)\n",
    "            \n",
    "#             index_s = np.where((eigen_features_s_i[:, 10] > 0.6) & (eigen_features_s_i[:, 8] < 0.6))[0]\n",
    "#             pc_s_i = pc_s_i[index_s, :]\n",
    "#             eigen_features_s_i = eigen_features_s_i[index_s, :]\n",
    "#             index_t = np.where((eigen_features_t_i[:, 10] > 0.6) & (eigen_features_t_i[:, 8] < 0.6))[0]\n",
    "#             pc_t_i = pc_t_i[index_t, :]\n",
    "#             eigen_features_t_i = eigen_features_t_i[index_t, :]\n",
    "#             print(pc_s_i.shape)\n",
    "#             print(pc_t_i.shape)\n",
    "            if pc_s_i.shape[0] < 64 or pc_t_i.shape[0] < 64:\n",
    "                T_total[int(i), :, :] = np.eye(4)\n",
    "            else:\n",
    "                T_total[int(i), :, :] = generate_transformation_matrix(pc_s_i, pc_t_i, attribute_s_i, attribute_t_i, pointhop)\n",
    "    \n",
    "    for i, pc in enumerate(pc_s_w):\n",
    "        if inst_label_new_new[i] > -1:\n",
    "            pc_s_w[i] = get_transformation_result(pc, T_total[int(inst_label_new_new[i])])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "#     pc_s[:, [1, 2]] = pc_s[:, [2, 1]]\n",
    "#     pc_t[:, [1, 2]] = pc_t[:, [2, 1]]\n",
    "#     pc_s_w[:, [1, 2]] = pc_s_w[:, [2, 1]]\n",
    "    flow_estimate = np.asarray(flow_estimate + (pc_s_w - pc_s))\n",
    "    \n",
    "    np.savez_compressed(os.path.join('\\\\Workspace\\\\SceneFlow\\\\datasets', 'stereoKITTI_flow', '{}.npz'.format(str(j).zfill(6))),\n",
    "                        flow_gt=flow_gt,\n",
    "                        flow_estimate=flow_estimate)\n",
    "    print(j)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644c1fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_consecutive_point_cloud(pc_s_w, pc_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moving_objects(pc_s, inst_label, inst_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_result(pc_s, pc_s_w, pc_t):\n",
    "    pcd_s = o3d.geometry.PointCloud()\n",
    "    pcd_s.points = o3d.utility.Vector3dVector(pc_s[:, 0:3])\n",
    "    pcd_s.paint_uniform_color([227/255, 23/255, 13/255])\n",
    "    \n",
    "    pcd_s_w = o3d.geometry.PointCloud()\n",
    "    pcd_s_w.points = o3d.utility.Vector3dVector(pc_s_w[:, 0:3])\n",
    "    pcd_s_w.paint_uniform_color([61/255, 89/255, 171/255])\n",
    "\n",
    "    pcd_t = o3d.geometry.PointCloud()\n",
    "    pcd_t.points = o3d.utility.Vector3dVector(pc_t[:, 0:3])\n",
    "    pcd_t.paint_uniform_color([0/255, 201/255, 87/255])\n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcd_s, pcd_t])\n",
    "    o3d.visualization.draw_geometries([pcd_s_w, pcd_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_result(pc_s_s, pc_s_w, pc_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb78fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scene_flow_EPE_np(pred, labels):\n",
    "    error = np.sqrt(np.sum((pred - labels)**2, 1) + 1e-20)\n",
    "\n",
    "    gtflow_len = np.sqrt(np.sum(labels*labels, 1) + 1e-20) # B,N\n",
    "    acc1 = np.sum(np.logical_or((error <= 0.05), (error/gtflow_len <= 0.05)))\n",
    "    acc2 = np.sum(np.logical_or((error <= 0.1), (error/gtflow_len <= 0.1)))\n",
    "    acc3 = np.sum(np.logical_or((error > 0.3), (error/gtflow_len > 0.05)))\n",
    "\n",
    "    num = pred.shape[0]\n",
    "    acc1 = acc1 / num\n",
    "    acc2 = acc2 / num\n",
    "    acc3 = acc3 / num\n",
    "\n",
    "    EPE = np.mean(error)\n",
    "    return EPE, acc1, acc2, acc3\n",
    "\n",
    "print(scene_flow_EPE_np(flow_estimate, flow_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99aefa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
